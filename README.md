# MNIST--American-Sign-Language-
This data set was adopted from the MNIST sign language, converting the CSV file into images and also decreasing the overall size of the database.  There are total 27,455 grayscale images of size 28 * 28 pixels whose value ranges from 0-255. Each case represents a label (0-25) as a one-to-one map for each alphabetic letter A-Z (and no cases for 9=J or 25=Z due to gestural movements).  The data is stored in an orderly fashion and is supported for use with dataflow generators in the TensorFlow API. Each folder is named according to the kind of images stored inside it, making it easy to load and view.  Images are stored in 'JPEG' file format.  The original hand gesture image data represented multiple users who repeated the gesture with different backgrounds. The MNIST data in sign language comes from a large extension of the small number (1704) of color images included as uncropped around the hand region of interest.  To create new data, an image pipeline based on ImageMagick was used and included cropping to just hands, gray scaling, resizing, and then creating at least 50+ variations to increase the amount. Modifying and expanding strategy were filters ('Mitchell', 'Robidoux', 'Catrom', 'Spline', 'Hermite'), along with 5% random pixilation, +/- 15% brightness/contrast and finally 3 degrees of rotation. Due to the small size of the images, these mods effectively alter resolution and class spacing in interesting and controllable ways.  Source: TecPerson - Kaggle
